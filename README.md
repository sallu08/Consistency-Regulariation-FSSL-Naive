# Consitency-Regulariation-FSSL-
To overcome data defficiency we make use of unlabeled data. But to ensure that this data is useful we use Consistency Regularization technique in which we create a duplicate set of our exisitng data and some noise is added. Purpose is to make model robust to noise. Original data predictions are used as True label for noisy data so that predictions for noisy dataset are closer to original. This technique is called consistency regularization or  consistency training. In this case we have 2 labeled client and three unlabeled clients. Then weights of all clients are shared with central server to create a robust and improved Global Model.
It is recommended to check the following example(https://github.com/sallu08/Federated-Learning) to understand simple implementation of Federated Learning first on Flower Platform.
Data used is MNIST. for unlabeled clients i have used my locally trained model ('my_modeli.h5') but you can relplace it with other model such as covenet etc.
